---
---

@article{ICAART2021,
  abbr={ICAART},
  title={Twin-GAN for Neural Machine Translation},
  author={Zhao, J. and Huang, L. and Sun, R. and Bing, L. and Qu, H.},
  abstract={In recent years, Neural Machine Translation (NMT) has achieved great success, but we can not ignore two
important problems. One is the exposure bias caused by the different strategies between training and inference, and the other is that the NMT model generates the best candidate word for the current step yet a bad
element of the whole sentence. The popular methods to solve these two problems are Schedule Sampling and
Generative Adversarial Networks (GANs) respectively, and both achieved some success. In this paper, we
proposed a more precise approach called “similarity selection” combining a new GAN structure called twinGAN to solve the above two problems. There are two generators and two discriminators in the twin-GAN.
One generator uses the “similarity selection” and the other one uses the same way as inference (simulate the
inference process). One discriminator guides generators at the sentence level, and the other discriminator
forces these two generators to have similar distributions. Moreover, we performed a lot of experiments on the
IWSLT 2014 German→English (De→En) and the WMT’17 Chinese→English (Zh→En) and the result shows
that we improved the performance compared to some other strong baseline models which based on recurrent
architecture.},
  journal={ICAART,},
  pages={87--96},
  numpages={0},
  year={2021},
  month={Feb},
  publisher="ICAART",
  doi={10.5220/0010217300870096},
  html={https://www.scitepress.org/Papers/2021/102173/102173.pdf},
  selected={true}
}

@article{sun2019evaluation,
  abbr={GT2019},
  title={An Evaluation of the Value of Lip and Jaw Motion in Virtual Reality Avatars},
  author={Sun, Ruixuan},
  abstract={Virtual reality (VR) is known as a simulated 3D immersive technology. Currently, the emphasis has been mainly placed on tracking the upper face, like eye tracking and eyebrow imitation, where the lower face containing the largest emotions of the face are usually hard for commercial VR headset to capture due to hardware limit. In this study, we explore the role of lip and jaw motionswhen VR is used as a communication medium by comparing the effectiveness of camera-based facial landmark tracking against audio-driven lip movements.},
  year={2019},
  publisher={Georgia Institute of Technology},
  html={https://smartech.gatech.edu/bitstream/handle/1853/61405/SUN-UNDERGRADUATERESEARCHOPTIONTHESIS-2019.pdf?sequence=1},
  selected={true}
}
