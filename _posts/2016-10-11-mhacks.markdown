---
title: "OrchestrAI @ Mhacks"
layout: post
date: 2016-10-09
# tag: jekyll
# image: /assets/images/jekyll-logo-light-solid.png
headerImage: true
projects: true
coursework: false
research: false
awards: false
hidden: true # don't count this post in blog pagination
description: "An improvisational AI that unleashes the creative power of an entire orchestra to music producers and artists."
#jemoji: '<img class="emoji" title=":ramen:" alt=":ramen:" src="https://assets.github.com/images/icons/emoji/unicode/1f35c.png" height="20" width="20" align="absmiddle">'
author: azra-ismail
externalLink: false

---

My team built an AI orchestra, capable of improvising musical pieces in real time, inspiring and adapting to the humans it is playing with, and generating completely new songs based on its experience. We organized these three capabilities under two distinct pipelines within our platform.

Ad Hoc improvisation and procedural generation was accomplished through our Neural Pipeline. I worked on the real-time playing and implemented the hardware and signal processing parts of the project. Real-time adaptive playing was accomplished through the Improvisational Pipeline. The real-time part consisted of an Arduino and two microphones (one from a set of Apple ear pods) mounted to a classical violin, which picked up the notes being played on the violin. We isolated these notes by sampling based on the beat. The note itself was determined by running a Fast Fourier Transform on the signal received and then extracting the most prominent frequency (a note is essentially a particular frequency). Finally, these extracted notes were mapped to new notes based on Music Theory, using concepts such as the pentatonic scale, perfect fourths, etc.

#### Tags

- Python
- Signal Processing
- Arduino
- Wolfram Alpha API

---

[Check it out](http://devpost.com/software/orchestrai) here.
If you need some help, just [tell me](http://github.com/aismail1997/aismail1997.github.io/issues).
